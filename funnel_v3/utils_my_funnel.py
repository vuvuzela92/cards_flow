import os
import json
import aiohttp
import asyncio
import pandas as pd
from datetime import datetime, timedelta
import gspread
from time import time
from calendar import monthrange
import logging
from dotenv import load_dotenv
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError
from utils_sql import create_connection, get_db_table
from gspread_dataframe import set_with_dataframe
from datetime import datetime
import os


# === –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø ===
logger = logging.getLogger("funnel_logger")
logger.setLevel(logging.INFO)

# –§–æ—Ä–º–∞—Ç—Ç–µ—Ä
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(funcName)s - %(message)s')

# 1. –•–µ–Ω–¥–ª–µ—Ä –≤ –§–ê–ô–õ
file_handler = logging.FileHandler('funnel.log', encoding='utf-8')
file_handler.setFormatter(formatter)
file_handler.setLevel(logging.INFO)

# 2. –•–µ–Ω–¥–ª–µ—Ä –≤ –ö–û–ù–°–û–õ–¨
console_handler = logging.StreamHandler()
console_handler.setFormatter(formatter)
console_handler.setLevel(logging.INFO)

# –î–æ–±–∞–≤–ª—è–µ–º –æ–±–∞ —Ö–µ–Ω–¥–ª–µ—Ä–∞
logger.addHandler(file_handler)
logger.addHandler(console_handler)


def load_api_tokens():
    # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞
    tokens_path = os.path.join(os.path.dirname(__file__), 'tokens.json')
    with open(tokens_path, 'r', encoding='utf-8') as f:
        return json.load(f)
    

def get_first_and_last_day(month: int):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–≤—É—é –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É –º–µ—Å—è—Ü–∞ –ø–æ –Ω–æ–º–µ—Ä—É –º–µ—Å—è—Ü–∞ –∏ –≥–æ–¥—É.
    
    Args:
        year (int): –ì–æ–¥ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2025)
        month (int): –ú–µ—Å—è—Ü (1‚Äì12)
    
    Returns:
        tuple: (–ø–µ—Ä–≤–∞—è_–¥–∞—Ç–∞, –ø–æ—Å–ª–µ–¥–Ω—è—è_–¥–∞—Ç–∞) –≤ —Ñ–æ—Ä–º–∞—Ç–µ datetime.date
    """
    year = datetime.now().year

    # –ü–µ—Ä–≤–æ–µ —á–∏—Å–ª–æ –º–µ—Å—è—Ü–∞
    first_day = datetime(year, month, 1).date()
    
    # –ü–æ—Å–ª–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ –º–µ—Å—è—Ü–∞ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º monthrange
    last_day_num = monthrange(year, month)[1]
    last_day = datetime(year, month, last_day_num).date()
    
    return first_day, last_day

    
def safe_open_spreadsheet(title, retries=5, delay=5):
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è –æ—Ç–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø—Ä–∏ APIError 503.
    """
    gc = gspread.service_account(filename=os.path.join(os.path.dirname(__file__), 'creds.json'))
    
    for attempt in range(1, retries + 1):
        logging.info(f"[–ü–æ–ø—ã—Ç–∫–∞ {attempt}] –æ—Ç–∫—Ä—ã—Ç—å –¥–æ—Å—Ç—É–ø –∫ —Ç–∞–±–ª–∏—Ü–µ '{title}'")
        
        try:
            spreadsheet = gc.open(title)
            logging.info(f"‚úÖ –¢–∞–±–ª–∏—Ü–∞ '{title}' —É—Å–ø–µ—à–Ω–æ –æ—Ç–∫—Ä—ã—Ç–∞")
            return spreadsheet
            
        except gspread.APIError as e:
            error_code = e.response.status_code if hasattr(e, 'response') else None
            logging.info(f"‚ö†Ô∏è [–ü–æ–ø—ã—Ç–∫–∞ {attempt}/{retries}] APIError {error_code}: {e}")
            
            if error_code == 503:
                if attempt < retries:
                    logging.info(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ {delay} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π...")
                    time.sleep(delay)
                    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–∏ (exponential backoff)
                    delay *= 2
                else:
                    logging.error("‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã")
                    raise
            else:
                # –î—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏ API (403, 404 –∏ —Ç.–¥.) - –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–µ–º
                raise
                
        except gspread.SpreadsheetNotFound:
            logging.info(f"‚ùå –¢–∞–±–ª–∏—Ü–∞ '{title}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            raise
            
        except Exception as e:
            logging.error(f"‚ö†Ô∏è [–ü–æ–ø—ã—Ç–∫–∞ {attempt}/{retries}] –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            if attempt < retries:
                logging.error(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ {delay} —Å–µ–∫—É–Ω–¥...")
                time.sleep(delay)
                delay *= 2
            else:
                raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É '{title}' –ø–æ—Å–ª–µ {retries} –ø–æ–ø—ã—Ç–æ–∫.")

async def get_funnel_v3(date_start: None, date_end: None, account: str, api_token: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –≤–æ—Ä–æ–Ω–∫–µ –ø—Ä–æ–¥–∞–∂ Wildberries"""
    products_list = []
    headers = {"Authorization": api_token}
    normal_delay = 2
    retry_delay = 20
    url = "https://seller-analytics-api.wildberries.ru/api/analytics/v3/sales-funnel/products"
    start = date_start
    end = date_end
    limit = 1000
    offset = 0
    max_attempts = 10
    attempt = 0

    async with aiohttp.ClientSession(headers=headers) as session:
        while True:
            payload = {
                "selectedPeriod": {
                    "start": start.strftime("%Y-%m-%d"),
                    "end": end.strftime("%Y-%m-%d")
                },
                "limit": limit,
                "offset": offset
            }

            try:
                async with session.post(url, json=payload) as res:
                    if res.status == 200:
                        data = await res.json()
                        products = data.get("data", {}).get("products", [])

                        if not products:
                            logging.info(f"üì≠ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {account}")
                            break

                        for p in products:
                            p["account"] = account
                        products_list.extend(products)

                        logging.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(products_list)} —Ç–æ–≤–∞—Ä–æ–≤ ({len(products)} –Ω–æ–≤—ã—Ö) –¥–ª—è {account} –∑–∞ –ø–µ—Ä–∏–æ–¥ {payload['selectedPeriod']}")

                        if len(products) < limit:
                            break

                        offset += len(products)
                        attempt = 0
                        await asyncio.sleep(normal_delay)

                    elif res.status == 429:
                        logging.info(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ 429 –¥–ª—è {account}: —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤, –∂–¥–µ–º {retry_delay} —Å–µ–∫.")
                        await asyncio.sleep(retry_delay)
                        attempt += 1
                        if attempt >= max_attempts:
                            logging.info(f"üö´ –ü—Ä–µ–≤—ã—à–µ–Ω–æ —á–∏—Å–ª–æ –ø–æ–ø—ã—Ç–æ–∫ ({max_attempts}) –¥–ª—è {account}")
                            break
                        continue

                    elif res.status in (400, 401, 403):
                        err = await res.json()
                        logging.info(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ {res.status} –¥–ª—è {account}: {err.get('detail', '–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞')}")
                        return None

                    else:
                        logging.info(f"‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å {res.status} –¥–ª—è {account}")
                        attempt += 1
                        if attempt >= max_attempts:
                            break

            except aiohttp.ClientError as err:
                logging.info(f"üåê –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞: {err}")
                attempt += 1
                if attempt >= max_attempts:
                    break

            except Exception as e:
                logging.info(f"üí• –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
                break

    if products_list:
        logging.info(f"üü¢ –ó–∞–≤–µ—Ä—à–µ–Ω–æ –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ {account}. –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(products_list)}")
        return products_list
    else:
        logging.info(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ –≤–æ—Ä–æ–Ω–∫–µ –ø—Ä–æ–¥–∞–∂ –¥–ª—è {account}")
        return None

async def fetch_all(date_start: int, date_end: None):
    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–Ω–∏–∫ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ—Å—Ç–∞–≤–∫–∞—Ö –ø–æ –≤—Å–µ–º –∞–∫–∫–∞—É–Ω—Ç–∞–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
    tasks = [get_funnel_v3(date_start, date_end, account, api_token) for account, api_token in load_api_tokens().items()]
    res = await asyncio.gather(*tasks)
    return res


async def process_funnel_month():
    """
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è: —Å–æ–±–∏—Ä–∞–µ–º –í–°–ï –¥–∞–Ω–Ω—ã–µ –≤ –æ–¥–∏–Ω DataFrame –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Å—è—Ü–µ–≤
    """
    # === 1. –ü–û–õ–£–ß–ê–ï–ú –î–ê–¢–´ –î–õ–Ø 12 –ú–ï–°–Ø–¶–ï–í –¥–æ —Ç–µ–∫—É—â–µ–≥–æ ===
    current_month = datetime.now().month
    date_ranges = []
    for month_num in range(0, 2):
        year = datetime.now().year
        month = current_month - month_num
        if month <= 0:
            month += 12
            year -= 1
        first_date, last_date = get_first_and_last_day(month)
        if month == current_month:
            last_date = (datetime.now()-timedelta(days=1)).date()
        date_ranges.append((first_date, last_date))
    
    logging.info(f"üìÖ –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ {len(date_ranges)} –º–µ—Å—è—Ü–µ–≤...")
    
    # === 2. –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–´–ô –ó–ê–ü–†–û–° –í–°–ï–• –ú–ï–°–Ø–¶–ï–í ===
    tasks = [fetch_all(first, last) for first, last in date_ranges]
    results = await asyncio.gather(*tasks)
    
    logging.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {sum(len(r) for r in results)} –∑–∞–ø–∏—Å–µ–π")
    
    # === 3. –û–ë–™–ï–î–ò–ù–Ø–ï–ú –í–°–ï –î–ê–ù–ù–´–ï –í –û–î–ò–ù –°–ü–ò–°–û–ö ===
    all_products = []
    for result in results:
        for acc_data in result:
            if acc_data:
                all_products.extend(acc_data)
    
    logging.info(f"üì¶ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(all_products)} —Ç–æ–≤–∞—Ä–æ–≤")
    
    # === 4. –û–ë–†–ê–ë–û–¢–ö–ê –í–°–ï–• –î–ê–ù–ù–´–• ===
    rows = []
    for product in all_products:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ 
        prod_info = product.get("product", {})
        stat = product.get("statistic", {})
        selected = stat.get("selected", {})
        time_to_ready = selected.get("timeToReady", {})
        
        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        row = {
            "account": product.get("account"),
            "nm_id": prod_info.get("nmId"),
            "vendor_code": prod_info.get("vendorCode"),  
            "title": prod_info.get("title"),
            "subject_id": prod_info.get("subjectId"),
            "subject_name": prod_info.get("subjectName"),
            "brand_name": prod_info.get("brandName"),
            "product_rating": prod_info.get("productRating"),
            "feedback_rating": prod_info.get("feedbackRating"),
            "stocks_wb": prod_info.get("stocks", {}).get("wb"),
            "stocks_mp": prod_info.get("stocks", {}).get("mp"),
            "balance_sum": prod_info.get("stocks", {}).get("balanceSum"),
        }
        
        # –ú–µ—Ç—Ä–∏–∫–∏ selected
        row.update({
            "open_count": selected.get("openCount"),
            "cart_count": selected.get("cartCount"),
            "order_count": selected.get("orderCount"),
            "orders_sum": selected.get("orderSum"),
            "buyout_count": selected.get("buyoutCount"),
            "buyout_sum": selected.get("buyoutSum"),
            "cancel_count": selected.get("cancelCount"),
            "cancel_sum": selected.get("cancelSum"),
            "avg_price": selected.get("avgPrice"),
            "avg_orders_count_per_day": selected.get("avgOrdersCountPerDay"),
            "share_order_percent": selected.get("shareOrderPercent"),
            "add_to_wish_list": selected.get("addToWishlist"),
            "time_to_ready": (
                time_to_ready.get("days", 0) * 24 * 60 +
                time_to_ready.get("hours", 0) * 60 +
                time_to_ready.get("mins", 0)
            ),
            "localization_percent": selected.get("localizationPercent"),
            "date": selected.get("period", {}).get("end"),
        })
        
        rows.append(row)
            
    # === 5. –û–î–ò–ù DataFrame ===
    df_full = pd.DataFrame(rows)
    
    # === 6. –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ ===
    df_full['month'] = pd.to_datetime(df_full['date']).dt.strftime('%m-%Y')
    df_full['wild'] = df_full['vendor_code'].str.extract(r'(wild\d+)')
    
    logging.info(f"‚ö° DataFrame —Å–æ–∑–¥–∞–Ω: {len(df_full)} —Å—Ç—Ä–æ–∫ –∑–∞ {len(date_ranges)} –º–µ—Å—è—Ü–µ–≤")
    
    return df_full

def create_insert_table_db_sync(df: pd.DataFrame, table_name: str, columns_type: dict, key_columns: tuple):
    load_dotenv()
    
    user = os.getenv('USER_2')
    password = os.getenv('PASSWORD_2')
    database = os.getenv('NAME_2') 
    host = os.getenv('HOST_2')
    port = os.getenv('PORT_2')
    
    connection_string = f"postgresql://{user}:{password}@{host}:{port}/{database}"
    engine = None
    
    try:
        engine = create_engine(connection_string)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
        valid_types = ['INTEGER', 'BIGINT', 'SMALLINT', 'NUMERIC', 'DATE', 'TIMESTAMP', 'BOOLEAN', 'TEXT', 'VARCHAR']
        for col, dtype in columns_type.items():
            if not dtype.strip():
                raise ValueError(f"–ü—É—Å—Ç–æ–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ {col}")
            base_type = dtype.split('(')[0].strip().upper()
            if base_type not in valid_types:
                raise ValueError(f"–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ {col}: {dtype}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
        missing_cols = set(columns_type.keys()) - set(df.columns)
        for col in missing_cols:
            df[col] = None
            logging.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∞—è –∫–æ–ª–æ–Ω–∫–∞ {col} —Å None")
        
        extra_cols = set(df.columns) - set(columns_type.keys())
        if extra_cols:
            logging.warning(f"–õ–∏—à–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ DataFrame: {extra_cols}, –æ–Ω–∏ –±—É–¥—É—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã")

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ SQL –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã
        columns_definition = ", ".join([f"{col} {dtype}" for col, dtype in columns_type.items()])
        unique_constraint = f", CONSTRAINT unique_{table_name} UNIQUE ({', '.join(key_columns)})" if key_columns else ""

        create_table_query = f"""
            CREATE TABLE IF NOT EXISTS {table_name} (
                {columns_definition}{unique_constraint}
            )
        """

        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
        with engine.connect() as conn:
            conn.execute(text(create_table_query))
            conn.commit()
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
        columns = list(columns_type.keys())
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è UPSERT
        temp_table = f"temp_{table_name}"
        
        # –í—Å—Ç–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
        df[columns].to_sql(temp_table, engine, if_exists='replace', index=False)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º UPSERT –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã —Å —è–≤–Ω—ã–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º —Ç–∏–ø–æ–≤
        with engine.connect() as conn:
            if key_columns:
                # –§–æ—Ä–º–∏—Ä—É–µ–º SELECT —Å —è–≤–Ω—ã–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º —Ç–∏–ø–æ–≤
                select_columns = []
                for col in columns:
                    if columns_type[col].upper() == 'TIMESTAMP':
                        select_columns.append(f"CAST({col} AS TIMESTAMP)")  # –Ø–≤–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
                    else:
                        select_columns.append(col)
                
                updates = ', '.join([f"{col}=EXCLUDED.{col}" for col in columns if col not in key_columns])
                upsert_query = f"""
                    INSERT INTO {table_name} ({', '.join(columns)})
                    SELECT {', '.join(select_columns)} FROM {temp_table}
                    ON CONFLICT ({', '.join(key_columns)}) 
                    DO UPDATE SET {updates}
                """
            else:
                # –ü—Ä–æ—Å—Ç–∞—è –≤—Å—Ç–∞–≤–∫–∞ —Å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º —Ç–∏–ø–æ–≤
                select_columns = []
                for col in columns:
                    if columns_type[col].upper() == 'TIMESTAMP':
                        select_columns.append(f"CAST({col} AS TIMESTAMP)")
                    else:
                        select_columns.append(col)
                
                upsert_query = f"""
                    INSERT INTO {table_name} ({', '.join(columns)})
                    SELECT {', '.join(select_columns)} FROM {temp_table}
                """
            
            conn.execute(text(upsert_query))
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
            conn.execute(text(f"DROP TABLE {temp_table}"))
            conn.commit()
        
        logging.info(f"–£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –≤ {table_name}")
        
    except SQLAlchemyError as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –ë–î: {str(e)}")
        raise
    except Exception as e:
        logging.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        raise
    finally:
        if engine:
            engine.dispose()

# === –ò—Å–ø–æ–ª–Ω—è–µ–º–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤–æ—Ä–æ–Ω–∫–µ –ø—Ä–æ–¥–∞–∂ –ø–æ –º–µ—Å—è—Ü–∞–º ===
async def main_funnel():
    # === –ó–∞–ø—É—Å–∫–∞–µ–º –∏ —Ñ—É–Ω–∫—Ü–∏—é –∏ –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ ===
    df_result = await process_funnel_month()
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    df_result = df_result.drop_duplicates()
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫–æ–ª–æ–Ω–∫—É –∫ —Ç–∏–ø—É –¥–∞–Ω–Ω—ã—Ö –¥–∞—Ç–∞
    df_result['date'] = pd.to_datetime(df_result['date']).dt.date
    # === –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –ë–î ===
    table_name = 'funnel_month'
    columns_type = {
        'account': 'VARCHAR(255)',
        'nm_id': 'BIGINT',
        'vendor_code': 'VARCHAR(255)',
        'title': 'VARCHAR(255)',
        'subject_id': 'BIGINT',
        'subject_name': 'VARCHAR(255)',
        'brand_name': 'VARCHAR(255)',
        'product_rating': 'NUMERIC(5,2)',
        'feedback_rating': 'NUMERIC(5,2)',
        'stocks_wb': 'BIGINT',
        'stocks_mp': 'BIGINT',
        'balance_sum': 'BIGINT',
        'open_count': 'BIGINT',
        'cart_count': 'BIGINT',
        'order_count': 'BIGINT',
        'orders_sum': 'BIGINT',
        'buyout_count': 'BIGINT',
        'buyout_sum': 'BIGINT',
        'cancel_count': 'BIGINT',
        'cancel_sum': 'BIGINT',
        'avg_price': 'NUMERIC(12,2)',
        'avg_orders_count_per_day': 'NUMERIC(10,2)',
        'share_order_percent': 'NUMERIC(10,2)',
        'add_to_wish_list': 'BIGINT',
        'time_to_ready': 'BIGINT',
        'localization_percent': 'NUMERIC(10,2)',
        'date': 'DATE',
        'month': 'TEXT',
        'wild': 'TEXT'
    }

    # –ö–ª—é—á–µ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è UPSERT
    key_columns = ('nm_id', 'date', 'account')  # –∫–∞–∫ –ø–µ—Ä–≤–∏—á–Ω—ã–π –∫–ª—é—á
    create_insert_table_db_sync(df_result, table_name, columns_type, key_columns)
    print(f"–î–∞–Ω–Ω—ã–µ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –ë–î {table_name}")

def funnel_month_to_gs():
    """ –í—ã–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î funnel_month
    –≤ –≥—É–≥–ª-—Ç–∞–±–ª–∏—Ü—É"""
    # === –†–∞–±–æ—Ç–∞ —Å –ë–î
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
    name = os.getenv('NAME_2')
    user = os.getenv('USER_2')
    password = os.getenv('PASSWORD_2')
    host = os.getenv('HOST_2')
    port = os.getenv('PORT_2')
    table_name = "funnel_month"
    # –ü–æ–ª—É—á–∞–µ–º –Ω—É–∂–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    connection = create_connection(name, user, password, host, port)
    query_1 = f"""SELECT * FROM {table_name}
                WHERE "date" >= DATE_TRUNC('year', CURRENT_DATE)
                AND "date" <= CURRENT_DATE - INTERVAL '1 day';"""
    # –ü–æ–º–µ—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º
    df = get_db_table(query_1, connection)
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
    df_month_cols_order = ["nm_id", "brand_name", "title", "date", "open_count", "cart_count", "order_count", "orders_sum", "buyout_count", "buyout_sum",
                    "cancel_count", "cancel_sum", "avg_price", "avg_orders_count_per_day", "add_to_wish_list", "localization_percent", "time_to_ready", 
                    "stocks_mp", "stocks_wb", "wild", "account", "month"]
    df_month = df[df_month_cols_order]
    # df_month['month'] = df_month['month'].astype(str)
    # df_month['date'] = df_month['date'].astype(str)
    # df_month = df_month.astype(str)
    table = safe_open_spreadsheet("–ü–ª–∞–Ω –†–ö")
    sheet_profit = table.worksheet("–ë–î –í–æ—Ä–æ–Ω–∫–∞ –º–µ—Å—è—Ü")

    # –ü–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ –ª–∏—Å—Ç–∞
    sheet_profit.clear()
    # === 2. –ó–ê–ü–ò–°–´–í–ê–ï–ú DataFrame –¶–ï–õ–ò–ö–û–ú ===
    # –ú–µ—Ç–æ–¥ set_with_dataframe –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ gspread_dataframe
    set_with_dataframe(sheet_profit, df_month, resize=True)

    formatted_time = (datetime.now()).strftime("%Y-%m-%d %H:%M:%S")
    max_columns = sheet_profit.col_count
    sheet_profit.update_cell(1, max_columns, formatted_time)
    print("–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
